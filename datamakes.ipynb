{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693f0cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in! Access JWT: eyJ0eXAiOiJhdCtqd3QiLCJhbGciOiJFUzI1NksifQ.eyJzY29wZSI6ImNvbS5hdHByb3RvLmFjY2VzcyIsInN1YiI6ImRpZDpwbGM6enBsZzNpYmN5am5vZng2YTdqcWx1c3czIiwiaWF0IjoxNzQ2MjEwNTQ5LCJleHAiOjE3NDYyMTc3NDksImF1ZCI6ImRpZDp3ZWI6bGVjY2ludW0udXMtd2VzdC5ob3N0LmJza3kubmV0d29yayJ9.Yzmyt5Un8cI2tc8-296VG8KJq46FLKJenYs5w69vBpe1iqYw6AilHil5EDNLDo_nGTROUdHnvODJt1N1Pc_R-w\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "PDS_URL  = \"https://bsky.social\"            # make sure this matches where your account lives\n",
    "USERNAME = \"timmyjunchen.bsky.social\"        # include the ‚Äú.bsky.social‚Äù suffix\n",
    "PASSWORD = \"Abcd1234\" # use an App-Password if you have 2FA enabled\n",
    "API_BASE = f\"{PDS_URL}/xrpc/app.bsky.feed.searchPosts\"\n",
    "\n",
    "url     = f\"{PDS_URL}/xrpc/com.atproto.server.createSession\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\"identifier\": USERNAME, \"password\": PASSWORD}\n",
    "\n",
    "resp = requests.post(url, json=payload, headers=headers, timeout=10)\n",
    "\n",
    "data = resp.json()\n",
    "access_jwt = data[\"accessJwt\"]\n",
    "refresh_jwt = data.get(\"refreshJwt\")  # for refreshing later, if needed\n",
    "\n",
    "print(\"Logged in! Access JWT:\", access_jwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d553457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bluesky_posts(\n",
    "    jwt: str,\n",
    "    query: str,\n",
    "    limit: int = 25,\n",
    "    cursor: Optional[str] = None,\n",
    "    sort: str = \"latest\",\n",
    "    lang: Optional[str] = \"en\"\n",
    ") -> Tuple[List[Dict], Optional[str]]:\n",
    "    headers = {\"Authorization\": f\"Bearer {jwt}\"}\n",
    "    params = {\"q\": query, \"limit\": limit, \"sort\": sort}\n",
    "    if cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "    if lang:\n",
    "        params[\"lang\"] = lang\n",
    "\n",
    "    resp = requests.get(API_BASE, params=params, headers=headers, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    posts = []\n",
    "    for hit in data.get(\"posts\", []):\n",
    "        rec = hit\n",
    "        posts.append({\n",
    "            \"uri\":        rec[\"uri\"],\n",
    "            \"author\":     hit[\"author\"][\"handle\"],\n",
    "            \"text\":       rec[\"record\"].get(\"text\", \"\"),\n",
    "            \"created_at\": rec[\"record\"][\"createdAt\"],\n",
    "            \"reply_count\":   rec[\"replyCount\"],\n",
    "            \"like_count\":    rec[\"likeCount\"],\n",
    "            \"repost_count\":  rec[\"repostCount\"]\n",
    "        })\n",
    "\n",
    "    return posts, data.get(\"cursor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0fc013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def scrape_twitter_cli(query: str, limit: int = 50) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Calls `twscrape search <query> --limit <limit>`,\n",
    "    parses JSON-per-line stdout into dicts.\n",
    "    \"\"\"\n",
    "    cmd = [\"twscrape\", \"search\", query, f\"--limit={str(limit)}\"]\n",
    "    completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    tweets = []\n",
    "    for line in completed.stdout.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        rec = json.loads(line)\n",
    "        rec.update({\n",
    "            \"platform\": \"twitter\",\n",
    "            \"query\":    query\n",
    "        })\n",
    "        tweets.append(rec)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_dataset(\n",
    "    events_df: pd.DataFrame,\n",
    "    twitter_limit: int,\n",
    "    bluesky_limit: int,\n",
    "    access_jwt: str\n",
    ") -> pd.DataFrame:\n",
    "    records = []\n",
    "    num = 0\n",
    "    for _, ev in events_df.iterrows():\n",
    "        posts = []\n",
    "        query = f\"{ev['topic']} until:{ev['expiration_time']}\"\n",
    "\n",
    "        print(\"query: \", query)\n",
    "        try:\n",
    "            tw_recs = scrape_twitter_cli(query + \" lang:en\", limit=twitter_limit)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"twscrape failed for {query}: {e}\")\n",
    "            tw_recs = []\n",
    "        print(\"twit num\")\n",
    "        print(len(tw_recs))\n",
    "        for r in tw_recs:\n",
    "            posts.append(r[\"rawContent\"])\n",
    "\n",
    "        bs_recs, _ = search_bluesky_posts(access_jwt, query, limit=bluesky_limit)\n",
    "        print(\"bluesky num\")\n",
    "        print(len(bs_recs))\n",
    "        for r in bs_recs:\n",
    "            posts.append(r[\"text\"])\n",
    "\n",
    "        row = {f\"post_{i+1}\": txt for i, txt in enumerate(posts)}\n",
    "        records.append(row)\n",
    "        if num > 50:\n",
    "            print(\"iteration: \", num)\n",
    "            break\n",
    "        time.sleep(150)  # throttle\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "590f06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "KALSHI_EVENTS = \"https://api.elections.kalshi.com/trade-api/v2/events\"\n",
    "culture_series = [\"KXSPOTIFYD\"]#, \"KXGAMEAWARDS\"]\n",
    "events = []\n",
    "for ticker in culture_series:\n",
    "    cursor = None\n",
    "    while True:\n",
    "        params = dict(\n",
    "            limit=200,\n",
    "            cursor=cursor,\n",
    "            series_ticker=ticker,\n",
    "            with_nested_markets=True\n",
    "        )\n",
    "        payload = requests.get(KALSHI_EVENTS, params=params).json()\n",
    "        for ev in payload[\"events\"]:\n",
    "            for market in ev[\"markets\"]:\n",
    "                events.append({\n",
    "                    \"series\":      ticker,\n",
    "                    \"title\":       ev[\"title\"],\n",
    "                    \"topic\":  market[\"no_sub_title\"],\n",
    "                    \"result\": market[\"result\"],\n",
    "                    \"expiration_time\": market[\"expiration_time\"],\n",
    "                    \"yes_bid\": market[\"yes_bid\"],\n",
    "                })\n",
    "        cursor = payload.get(\"cursor\")\n",
    "        if not cursor:\n",
    "            break\n",
    "\n",
    "events_df = pd.DataFrame(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07a7a5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>result</th>\n",
       "      <th>expiration_time</th>\n",
       "      <th>yes_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top song on Spotify on Oct 29, 2024?</td>\n",
       "      <td>St. Chroma</td>\n",
       "      <td>yes</td>\n",
       "      <td>2024-11-12T14:00:00Z</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top song on Spotify USA Chart on Oct 30, 2024?</td>\n",
       "      <td>St. Chroma</td>\n",
       "      <td>yes</td>\n",
       "      <td>2024-11-13T14:00:00Z</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top song on Spotify USA Chart on Oct 31, 2024?</td>\n",
       "      <td>St. Chroma</td>\n",
       "      <td>no</td>\n",
       "      <td>2024-11-14T14:00:00Z</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top song on Spotify USA Chart on Oct 31, 2024?</td>\n",
       "      <td>Sticky</td>\n",
       "      <td>no</td>\n",
       "      <td>2024-11-14T14:00:00Z</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top song on Spotify USA Chart on Nov 1, 2024?</td>\n",
       "      <td>Darling, I</td>\n",
       "      <td>no</td>\n",
       "      <td>2024-11-15T14:00:00Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top USA Song on Spotify on Apr 26, 2025?</td>\n",
       "      <td>NOKIA</td>\n",
       "      <td>yes</td>\n",
       "      <td>2025-05-10T14:00:00Z</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top USA Song on Spotify on Apr 26, 2025?</td>\n",
       "      <td>What Was That</td>\n",
       "      <td>no</td>\n",
       "      <td>2025-05-10T14:00:00Z</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top USA Song on Spotify on May 2, 2025?</td>\n",
       "      <td>NOKIA</td>\n",
       "      <td></td>\n",
       "      <td>2025-05-16T14:00:00Z</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top USA Song on Spotify on May 2, 2025?</td>\n",
       "      <td>luther (with sza)</td>\n",
       "      <td></td>\n",
       "      <td>2025-05-16T14:00:00Z</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KXSPOTIFYD</td>\n",
       "      <td>Top USA Song on Spotify on May 2, 2025?</td>\n",
       "      <td>Ordinary</td>\n",
       "      <td></td>\n",
       "      <td>2025-05-16T14:00:00Z</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          series                                           title  \\\n",
       "2249  KXSPOTIFYD            Top song on Spotify on Oct 29, 2024?   \n",
       "2246  KXSPOTIFYD  Top song on Spotify USA Chart on Oct 30, 2024?   \n",
       "2240  KXSPOTIFYD  Top song on Spotify USA Chart on Oct 31, 2024?   \n",
       "2237  KXSPOTIFYD  Top song on Spotify USA Chart on Oct 31, 2024?   \n",
       "2236  KXSPOTIFYD   Top song on Spotify USA Chart on Nov 1, 2024?   \n",
       "...          ...                                             ...   \n",
       "116   KXSPOTIFYD        Top USA Song on Spotify on Apr 26, 2025?   \n",
       "109   KXSPOTIFYD        Top USA Song on Spotify on Apr 26, 2025?   \n",
       "30    KXSPOTIFYD         Top USA Song on Spotify on May 2, 2025?   \n",
       "22    KXSPOTIFYD         Top USA Song on Spotify on May 2, 2025?   \n",
       "20    KXSPOTIFYD         Top USA Song on Spotify on May 2, 2025?   \n",
       "\n",
       "                  topic result       expiration_time  yes_bid  \n",
       "2249         St. Chroma    yes  2024-11-12T14:00:00Z       95  \n",
       "2246         St. Chroma    yes  2024-11-13T14:00:00Z       99  \n",
       "2240         St. Chroma     no  2024-11-14T14:00:00Z       70  \n",
       "2237             Sticky     no  2024-11-14T14:00:00Z       10  \n",
       "2236         Darling, I     no  2024-11-15T14:00:00Z        2  \n",
       "...                 ...    ...                   ...      ...  \n",
       "116               NOKIA    yes  2025-05-10T14:00:00Z        9  \n",
       "109       What Was That     no  2025-05-10T14:00:00Z        2  \n",
       "30                NOKIA         2025-05-16T14:00:00Z       37  \n",
       "22    luther (with sza)         2025-05-16T14:00:00Z        9  \n",
       "20             Ordinary         2025-05-16T14:00:00Z       40  \n",
       "\n",
       "[327 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = events_df.iloc[::-1]\n",
    "events_df = events_df[events_df[\"yes_bid\"] > 1]\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de04ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  APT. until:2024-11-11T14:00:00Z\n",
      "twit num\n",
      "36\n",
      "bluesky num\n",
      "20\n",
      "query:  BIRDS OF A FEATHER until:2024-11-11T14:00:00Z\n",
      "twit num\n",
      "40\n",
      "bluesky num\n",
      "19\n",
      "2258\n"
     ]
    }
   ],
   "source": [
    "dataset_df = build_training_dataset(\n",
    "        events_df,\n",
    "        twitter_limit=20,\n",
    "        bluesky_limit=20,\n",
    "        access_jwt=access_jwt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b39b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_1</th>\n",
       "      <th>post_2</th>\n",
       "      <th>post_3</th>\n",
       "      <th>post_4</th>\n",
       "      <th>post_5</th>\n",
       "      <th>post_6</th>\n",
       "      <th>post_7</th>\n",
       "      <th>post_8</th>\n",
       "      <th>post_9</th>\n",
       "      <th>post_10</th>\n",
       "      <th>...</th>\n",
       "      <th>post_50</th>\n",
       "      <th>post_51</th>\n",
       "      <th>post_52</th>\n",
       "      <th>post_53</th>\n",
       "      <th>post_54</th>\n",
       "      <th>post_55</th>\n",
       "      <th>post_56</th>\n",
       "      <th>post_57</th>\n",
       "      <th>post_58</th>\n",
       "      <th>post_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well now I need her on an actual APT remix</td>\n",
       "      <td>I‚Äôm screaming https://t.co/9crPBGagzJ</td>\n",
       "      <td>@rykyok furry feet 2 is peak though i think th...</td>\n",
       "      <td>@JhayCripzzyy @xabierablume @chuubry not rlly,...</td>\n",
       "      <td>@Jukes_TV @elonmusk Rand Paul not exactly a te...</td>\n",
       "      <td>What folk are more apt to go native first?</td>\n",
       "      <td>üö®#WATCH: As Chaos and Shocked Travelers Witnes...</td>\n",
       "      <td>@asianjunkiecom My dad and brother sent me APT...</td>\n",
       "      <td>üö®üö®911 Emergency!\\n üö®üö®Posted in Self-Defense!\\n...</td>\n",
       "      <td>will never get the obsession w numbers. tbh id...</td>\n",
       "      <td>...</td>\n",
       "      <td>aint even left my apt yet and I already wanna ...</td>\n",
       "      <td>Fool aid is such an apt descriptor.</td>\n",
       "      <td>Afternoon Bluesky.  Very apt I joined yesterda...</td>\n",
       "      <td>I deep cleaned the fuck out of my apt. Like to...</td>\n",
       "      <td>arrrrgghh! got a new light up vanity for my ap...</td>\n",
       "      <td>In Pa, they believe every word. Gas and rent w...</td>\n",
       "      <td>instructions unclear !!\\n\\ni did finally join ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PInsider_ Birds of a feather obviously</td>\n",
       "      <td>@AMAZlNGNATURE Birds of a feather, Ducks in a ...</td>\n",
       "      <td>Don‚Äôt be rash. There are pockets of love and p...</td>\n",
       "      <td>For those who are thinking about leaving Twitt...</td>\n",
       "      <td>@mikepompeo @SpeakerJohnson ‚ÄúPower of the Purs...</td>\n",
       "      <td>birds of a feather really do flock together th...</td>\n",
       "      <td>@GuntherEagleman Birds of a feather</td>\n",
       "      <td>fuck it. idc if theres already one, when s6 en...</td>\n",
       "      <td>not birds of a feather playing on this</td>\n",
       "      <td>What kind of creature is this? ü¶ëüåäü§î https://t.c...</td>\n",
       "      <td>...</td>\n",
       "      <td>Horned Screamer, Amazonas, Colombia.\\n\\n#birds</td>\n",
       "      <td>How ironic ; or timely, that we all left toget...</td>\n",
       "      <td>‚ùÑÔ∏èüåª ironically, hrid gets along well with sky'...</td>\n",
       "      <td>I also dont want to be associated with that il...</td>\n",
       "      <td>My Grammy rankings:\\n\\n1) Good Luck Babe ‚Äî Cha...</td>\n",
       "      <td>A masked bandit (OK, a juvenile #Nuthatch) abo...</td>\n",
       "      <td>sometimes i flip in between of thinking, \"am i...</td>\n",
       "      <td>Birds of a feather flock together, unsurprisin...</td>\n",
       "      <td>Great Blue Heron hunting for food at low tide....</td>\n",
       "      <td>trump pretended to give a microphone a blowjob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       post_1  \\\n",
       "0  well now I need her on an actual APT remix   \n",
       "1     @PInsider_ Birds of a feather obviously   \n",
       "\n",
       "                                              post_2  \\\n",
       "0              I‚Äôm screaming https://t.co/9crPBGagzJ   \n",
       "1  @AMAZlNGNATURE Birds of a feather, Ducks in a ...   \n",
       "\n",
       "                                              post_3  \\\n",
       "0  @rykyok furry feet 2 is peak though i think th...   \n",
       "1  Don‚Äôt be rash. There are pockets of love and p...   \n",
       "\n",
       "                                              post_4  \\\n",
       "0  @JhayCripzzyy @xabierablume @chuubry not rlly,...   \n",
       "1  For those who are thinking about leaving Twitt...   \n",
       "\n",
       "                                              post_5  \\\n",
       "0  @Jukes_TV @elonmusk Rand Paul not exactly a te...   \n",
       "1  @mikepompeo @SpeakerJohnson ‚ÄúPower of the Purs...   \n",
       "\n",
       "                                              post_6  \\\n",
       "0         What folk are more apt to go native first?   \n",
       "1  birds of a feather really do flock together th...   \n",
       "\n",
       "                                              post_7  \\\n",
       "0  üö®#WATCH: As Chaos and Shocked Travelers Witnes...   \n",
       "1                @GuntherEagleman Birds of a feather   \n",
       "\n",
       "                                              post_8  \\\n",
       "0  @asianjunkiecom My dad and brother sent me APT...   \n",
       "1  fuck it. idc if theres already one, when s6 en...   \n",
       "\n",
       "                                              post_9  \\\n",
       "0  üö®üö®911 Emergency!\\n üö®üö®Posted in Self-Defense!\\n...   \n",
       "1             not birds of a feather playing on this   \n",
       "\n",
       "                                             post_10  ...  \\\n",
       "0  will never get the obsession w numbers. tbh id...  ...   \n",
       "1  What kind of creature is this? ü¶ëüåäü§î https://t.c...  ...   \n",
       "\n",
       "                                             post_50  \\\n",
       "0  aint even left my apt yet and I already wanna ...   \n",
       "1     Horned Screamer, Amazonas, Colombia.\\n\\n#birds   \n",
       "\n",
       "                                             post_51  \\\n",
       "0                Fool aid is such an apt descriptor.   \n",
       "1  How ironic ; or timely, that we all left toget...   \n",
       "\n",
       "                                             post_52  \\\n",
       "0  Afternoon Bluesky.  Very apt I joined yesterda...   \n",
       "1  ‚ùÑÔ∏èüåª ironically, hrid gets along well with sky'...   \n",
       "\n",
       "                                             post_53  \\\n",
       "0  I deep cleaned the fuck out of my apt. Like to...   \n",
       "1  I also dont want to be associated with that il...   \n",
       "\n",
       "                                             post_54  \\\n",
       "0  arrrrgghh! got a new light up vanity for my ap...   \n",
       "1  My Grammy rankings:\\n\\n1) Good Luck Babe ‚Äî Cha...   \n",
       "\n",
       "                                             post_55  \\\n",
       "0  In Pa, they believe every word. Gas and rent w...   \n",
       "1  A masked bandit (OK, a juvenile #Nuthatch) abo...   \n",
       "\n",
       "                                             post_56  \\\n",
       "0  instructions unclear !!\\n\\ni did finally join ...   \n",
       "1  sometimes i flip in between of thinking, \"am i...   \n",
       "\n",
       "                                             post_57  \\\n",
       "0                                                NaN   \n",
       "1  Birds of a feather flock together, unsurprisin...   \n",
       "\n",
       "                                             post_58  \\\n",
       "0                                                NaN   \n",
       "1  Great Blue Heron hunting for food at low tide....   \n",
       "\n",
       "                                             post_59  \n",
       "0                                                NaN  \n",
       "1  trump pretended to give a microphone a blowjob...  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "345b3f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timmy\\AppData\\Local\\Temp\\ipykernel_47684\\3433543020.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  compound_df = texts.applymap(lambda txt: analyzer.polarity_scores(txt)['compound'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_1</th>\n",
       "      <th>post_2</th>\n",
       "      <th>post_3</th>\n",
       "      <th>post_4</th>\n",
       "      <th>post_5</th>\n",
       "      <th>post_6</th>\n",
       "      <th>post_7</th>\n",
       "      <th>post_8</th>\n",
       "      <th>post_9</th>\n",
       "      <th>post_10</th>\n",
       "      <th>...</th>\n",
       "      <th>post_50</th>\n",
       "      <th>post_51</th>\n",
       "      <th>post_52</th>\n",
       "      <th>post_53</th>\n",
       "      <th>post_54</th>\n",
       "      <th>post_55</th>\n",
       "      <th>post_56</th>\n",
       "      <th>post_57</th>\n",
       "      <th>post_58</th>\n",
       "      <th>post_59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2732</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>-0.3147</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.5728</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>-0.3907</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_1  post_2  post_3  post_4  post_5  post_6  post_7  post_8  post_9  \\\n",
       "0  0.2732 -0.3818  0.0000   0.296  0.4404     0.0 -0.1779  0.3919 -0.3147   \n",
       "1  0.0000  0.0000 -0.4939   0.000  0.0000     0.0  0.0000 -0.5423  0.2023   \n",
       "\n",
       "   post_10  ...  post_50  post_51  post_52  post_53  post_54  post_55  \\\n",
       "0   0.7943  ...      0.0  -0.4404   0.9214  -0.2500  -0.5728   0.5927   \n",
       "1   0.0000  ...      0.0  -0.1280   0.2023  -0.0572   0.9311   0.5267   \n",
       "\n",
       "   post_56  post_57  post_58  post_59  \n",
       "0  -0.3907   0.0000   0.0000   0.0000  \n",
       "1   0.7337   0.7269   0.4767   0.3612  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import json\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "texts = dataset_df.astype(str)\n",
    "\n",
    "# 2) applymap over every cell, extracting only 'compound'\n",
    "compound_df = texts.applymap(lambda txt: analyzer.polarity_scores(txt)['compound'])\n",
    "compound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70ef3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_df[\"result\"] = events_df.iloc[::-1][\"result\"][:2].values\n",
    "compound_df[\"yes_bid\"] = events_df.iloc[::-1][\"yes_bid\"][:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27ee345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_1</th>\n",
       "      <th>post_2</th>\n",
       "      <th>post_3</th>\n",
       "      <th>post_4</th>\n",
       "      <th>post_5</th>\n",
       "      <th>post_6</th>\n",
       "      <th>post_7</th>\n",
       "      <th>post_8</th>\n",
       "      <th>post_9</th>\n",
       "      <th>post_10</th>\n",
       "      <th>...</th>\n",
       "      <th>post_52</th>\n",
       "      <th>post_53</th>\n",
       "      <th>post_54</th>\n",
       "      <th>post_55</th>\n",
       "      <th>post_56</th>\n",
       "      <th>post_57</th>\n",
       "      <th>post_58</th>\n",
       "      <th>post_59</th>\n",
       "      <th>result</th>\n",
       "      <th>yes_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2732</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>-0.3147</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.5728</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>-0.3907</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_1  post_2  post_3  post_4  post_5  post_6  post_7  post_8  post_9  \\\n",
       "0  0.2732 -0.3818  0.0000   0.296  0.4404     0.0 -0.1779  0.3919 -0.3147   \n",
       "1  0.0000  0.0000 -0.4939   0.000  0.0000     0.0  0.0000 -0.5423  0.2023   \n",
       "\n",
       "   post_10  ...  post_52  post_53  post_54  post_55  post_56  post_57  \\\n",
       "0   0.7943  ...   0.9214  -0.2500  -0.5728   0.5927  -0.3907   0.0000   \n",
       "1   0.0000  ...   0.2023  -0.0572   0.9311   0.5267   0.7337   0.7269   \n",
       "\n",
       "   post_58  post_59  result  yes_bid  \n",
       "0   0.0000   0.0000      no        1  \n",
       "1   0.4767   0.3612      no        0  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96100f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_df.to_csv(\"training_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
